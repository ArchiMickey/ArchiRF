hparams:
  seed: 42
  batch_size: 256
  grad_accumulate_every: 1
  lr: 1e-4
  # max_grad_norm: 1.
  n_steps: 400000
  # n_steps: 1
  use_ema: true
  ema_decay: 0.9999

datamodule:
  _partial_: true
  _target_: data.data_utils.ExperimentDataModule
  dataset_name: imagenet
  root: /mnt/g/ImageNet
  image_size: 64
  num_workers: 20

model:
  _target_: models.rf.LatentRectifiedFlow
  channels: 16
  image_size: 8
  logit_normal_sampling_t: true
  net:
    _target_: modules.networks_mmdit.MMDiT
    input_size: ${model.image_size}
  
    in_channels: ${model.channels}
    dim: 768
    depth: 12
    num_heads: 12
    num_classes: 1000

optimizer:
  _partial_: true
  _target_: bitsandbytes.optim.AdamW8bit
  lr: ${hparams.lr}
  weight_decay: 0.

lr_scheduler:
  _partial_: true
  _target_: modules.lr_scheduler.LinearWarmupLRSched
  warmup_steps: 1000

trainer:
  _partial_: true
  _target_: trainer.Trainer
  accelerator:
    _target_: accelerate.Accelerator
    mixed_precision: bf16
    log_with: wandb
  log_dir: ./logs/imagenet/lrf
  sampling_steps: 50
  save_interval: 50000
  sample_interval: 20000
  fid_eval_interval: 100000
  fid_stats_dir: ./results/imagenet
  fid_cfg_scale: 1.5
  num_fid_samples: 50000
  logger_kwargs:
    project_name: RF-Experiments
    init_kwargs:
      wandb:
        name: imagenet-lrf-mmdit