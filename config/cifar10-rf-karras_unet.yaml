hparams:
  seed: 42
  batch_size: 64
  grad_accumulate_every: 2
  lr: 0.012
  # max_grad_norm: torch.inf
  n_steps: 400000
  use_ema: true
  ema_decay: 0.9999

datamodule:
  _partial_: true
  _target_: data.data_utils.ExperimentDataModule
  dataset_name: cifar10
  random_horizonal_flip: true
  root: /mnt/g
  image_size: 32
  num_workers: 8

model:
  _target_: models.rf.RectifiedFlow
  channels: 3
  image_size: ${datamodule.image_size}
  logit_normal_sampling_t: true
  net:
    _target_: modules.networks_karras_unet.UNet
    img_resolution: 32
    img_channels: 3
    num_classes: 10
    model_channels: 128
    channel_mult: [1, 2, 2, 2] 

optimizer:
  _partial_: true
  _target_: bitsandbytes.optim.AdamW8bit
  lr: ${hparams.lr}
  weight_decay: 0.

lr_scheduler:
  _partial_: true
  _target_: modules.utils.InvSqrtDecayLRSched
  t_ref: 70000

trainer:
  _partial_: true
  _target_: trainer.Trainer
  accelerator:
    _target_: accelerate.Accelerator
    mixed_precision: bf16
    log_with: wandb
  log_dir: ./logs/cifar10/rf/karras_unet
  sampling_steps: 50
  save_interval: 50000
  sample_interval: 20000
  n_per_class: 10
  fid_eval_interval: 100000
  fid_stats_dir: ./results/cifar10
  fid_cfg_scale: 1.5
  num_fid_samples: 50000
  logger_kwargs:
    project_name: RF-Experiments
    init_kwargs:
      wandb:
        name: cifar10-rf-karras_unet