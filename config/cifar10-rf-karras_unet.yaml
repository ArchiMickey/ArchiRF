hparams:
  seed: 42
  batch_size: 128
  grad_accumulate_every: 1
  lr: 0.012
  # max_grad_norm: torch.inf
  n_steps: 400000
  use_ema: true
  ema_decay: 0.9999

datamodule:
  _partial_: true
  _target_: data.data_utils.ExperimentDataModule
  dataset_name: cifar10
  random_horizonal_flip: true
  root: /mnt/g
  image_size: 32
  num_workers: 8

model:
  _target_: models.rf.RectifiedFlow
  channels: 3
  image_size: ${datamodule.image_size}
  logit_normal_sampling_t: true
  net:
    _target_: modules.networks_karras_unet.KarrasUnet
    dim: 128
    dim_max: 512
    channels: 3
    dim_mults: [1, 2, 2, 2]
    num_blocks_per_stage: 3
    num_classes: 10
    attn_levels: [1, 2]
    fourier_dim: 128
    attn_dim_head: 64

optimizer:
  _partial_: true
  _target_: bitsandbytes.optim.AdamW8bit
  lr: ${hparams.lr}
  weight_decay: 0.

lr_scheduler:
  _partial_: true
  _target_: modules.utils.InvSqrtDecayLRSched
  t_ref: 70000

trainer:
  _partial_: true
  _target_: trainer.Trainer
  accelerator:
    _target_: accelerate.Accelerator
    mixed_precision: bf16
    log_with: wandb
  log_dir: ./logs/cifar10/rf/karras_unet
  sample_batch_size: 256
  sampling_steps: 50
  save_and_sample_interval: 20000
  # save_and_sample_interval: 1
  n_per_class: 10
  fid_eval_interval: 100000
  # fid_eval_interval: 1
  fid_stats_dir: ./results/cifar10
  fid_cfg_scale: 1.5
  num_fid_samples: 50000
  logger_kwargs:
    project_name: RF-Experiments
    init_kwargs:
      wandb:
        name: cifar10-rf-karras_unet